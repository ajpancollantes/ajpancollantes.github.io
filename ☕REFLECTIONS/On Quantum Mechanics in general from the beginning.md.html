<!DOCTYPE html>
<html>
<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LBT9E8N3HS"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LBT9E8N3HS');
</script>
<script> MathJax={tex:{inlineMath: [['$', '$']]}};</script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.3.1/languages/go.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<style>
	img { max-width:900px; }
	.codeblock { 
	background: #B0B0B0; padding:1px 10px 0px 10px; border-radius: 5px; overflow-x:auto; 
	}
	code {
 font-family: monospace; font-size: inherit; color: #202020; 
	}
	.inlineCoed {
 font-family: monospace; font-size: inherit; color: #202020; 
	}
</style>
</head>
<body style="background: #F0F0F0;">
<div style="width:90vw; padding:5vw; margin:0px; z-index: 5; text-align:left; background-color: #DCDCDC; border-radius: 5px; position:absolute; top:0; left:0px;">
<font size="3vw"><h1 style="margin-left:0px;" id="On_Quantum_Mechanics_from_the_beginning">On Quantum Mechanics from the beginning</h1>
<p>We assume, without definition, the following concepts: there exists a <b>system</b> (in a more general sense than <a href="./../♾️ CONCEPTS/dynamical system.md.html">dynamical system</a>s) which is made of <b>states</b>, and we can make <b>measurements</b> of different properties (<b>observables</b>) of the system, obtaining real values which depend on which state the system is. The system changes state (with respect to a parameter $t \in \mathbb N$ or $t\in \mathbb R$ which we call time) according to a <b>dynamical law</b>.</p>
<p></p>
<p>All this can be modelled, at least to my knowledge, in two ways:</p>
<p></p>
<h3 style="margin-left:0px;" id="Mathematical_model_1_MM1">Mathematical model 1 (MM1)</h3>
<p><ul style="margin-left:0px;"><li>We have a set $\Omega=\{a,b,c,d,\ldots\}$. Its elements are called the pure states of the system. We call this set the <b>phase space</b>.</li></ul></p>
<p><ul style="margin-left:0px;"><li>The observables are nothing but functions $f: \Omega \to \mathbb{R}$. The measurement process consists, simply, of evaluating the function. It is assumed that the measurement is "clean" in the sense that does not modify the state in which the system is.</li></ul></p>
<p><ul style="margin-left:0px;"><li>If we have "observables enough" we can have a bijection of $\Omega$ with a "numerical set".</li></ul></p>
<p><ul style="margin-left:0px;"><li>Probabilities. You can consider that the system is not in a pure state but in a mixed one, a kind of generalized state. As if you have a big box with lots of copies of the system, every of them in a different state. You repeat a measurement several times and you obtain several values, with a distribution of frequencies or probability. To my knowledge, there are two reasons to do this:</li></ul></p>
<p>	1. You are working with too many degrees of freedom (this is the trick of <a href="./../⛳️ NON CLASSIFIED/Classical Statistical Mechanics.md.html">Classical Statistical Mechanics</a> for avoiding too many dimensions.); or</p>
<p>	2. You assume that the measurement is not one hundred percent precise, and you repeat again and again obtaining a probability distribution. </p>
<p><ul style="margin-left:0px;"><li>Algebraic formulation: the observables (functions) live inside a complex commutative algebra $\mathcal F$. They can be seen like the main characters of the story, since it is what "we can access". If you can't measure the difference between two systems, you have no right to treat them as different. In mathematics there are lots of examples where a space is recovered from its algebra of functions, or at least from its <a href="./../♾️ CONCEPTS/ALGEBRAIC GEOMETRY/sheaf.md.html">sheaves</a>. This is the spirit of <a href="./Algebraic Geometry.md.html">Algebraic Geometry</a>. Important example: a space is <a href="./../♾️ CONCEPTS/locally compact.md.html">locally compact</a> Hausdorff iff its algebra of continuous functions is a commutative <a href="./../♾️ CONCEPTS/c-star algebra.md.html">c-star algebra</a>, and reciprocally any commutative c-star algebra is the algebra of continuous functions on some space (the <a href="./../♾️ CONCEPTS/Gelfand spectrum.md.html">Gelfand spectrum</a>). See <a href="./../Bibliography/@strocchi2008introduction.md.html">@strocchi2008introduction</a> page 15, <a href="./../✏️ THEOREMS/Gelfand-Naimark theorem.md.html">Gelfand-Naimark theorem</a>. In Classical Mechanics the observables constitute a commutative algebra $\mathcal F$ and the Gelfand spectrum $\Omega$ (multiplicative linear functionals on $\mathcal F$) are the pure states (<a href="./../Bibliography/@strocchi2008introduction.md.html">@strocchi2008introduction</a> page 13). The mixed states are the normalized positive linear functionals. The <a href="./Riesz-Markov representation theorem.md.html">Riesz-Markov representation theorem</a> let us assure that a mixed state $\omega$ in this sense determines a unique <a href="./../⛳️ NON CLASSIFIED/probability theory.md.html">probability distribution</a> $\mu_{\omega}$ on the <a href="./../♾️ CONCEPTS/Gelfand spectrum.md.html">Gelfand spectrum</a> (see <a href="./../Bibliography/@strocchi2008introduction.md.html">@strocchi2008introduction</a> page 13) such that for an observable $f$</li></ul></p>
$$
\omega(f)=\int_{\Omega} f d\mu_{\omega},\quad \mu_{\omega}(\Omega)=\omega(1)=1
$$
<p><ul style="margin-left:0px;"><li>Dynamics. Once we have the bijection with the numerical set, we usually formulate the dynamical law like a continuous or discrete <a href="./../♾️ CONCEPTS/dynamical system.md.html">dynamical system</a>. I have to develop this yet.</li></ul></p>
<p></p>
<p></p>
<h3 style="margin-left:0px;" id="Mathematical_model_2_MM2">Mathematical model 2 (MM2)</h3>
<p><ul style="margin-left:0px;"><li>The system consist of a <a href="./../♾️ CONCEPTS/FUNCTIONAL ANALYSIS/Hilbert space.md.html">Hilbert space</a> $(\mathcal{H},\langle -,- \rangle)$ whose elements of length 1 (or its rays, I am not sure) are the states of the system.</li></ul></p>
<p><ul style="margin-left:0px;"><li>The observables are <a href="./../♾️ CONCEPTS/Hermitian matrix.md.html">Hermitian operators</a> $\hat Q: \mathcal H \to \mathcal H$. The measurement process, provided we are in state $|\psi \rangle \in \mathcal H$, consists of</li></ul></p>
<p><ul style="margin-left:20px;"><li>obtaining the basis of eigenvectors $\{|q_i\rangle\}_i$ (with eigenvalues $q_i$) of the operator $\hat Q$.</li></ul></p>
<p><ul style="margin-left:20px;"><li>randomly selecting one of them, according to the probability distribution $P(|q_i\rangle)=|\langle q_i|\psi\rangle|^2$ , that is, $P(|q_i\rangle)=|c_i|^2$ where $|\psi\rangle=c_1|q_1\rangle+c_2|q_2\rangle+\cdots$</li></ul></p>
<p><ul style="margin-left:20px;"><li>applying the operator to the selected $|q_i\rangle$ and project the result over $|q_i\rangle$. In general we will call to the operation $\langle \psi |\hat Q |\psi \rangle$ the <b>expected value</b> of $\hat Q$ with respect to $|\psi\rangle$. In the case of eigenvectors this operation returns the eigenvalue.</li></ul></p>
<p>	The measurement has changed the state in which the system is, unless it were in one of the eigenvectors.</p>
<p><ul style="margin-left:0px;"><li>There is something called complete set of commuting observables. If you need more that one observable everything gets complicated, because you have eigenvalues with several eigenvectors (eigenspace of dimension greater than 1) and you maybe have to introduce tensor product to separate then and so on... Think of $x$ coordinate and $y$ coordinate in a discrete setup, for example. Key idea: commuting Hermitian operators have a common basis of eigenvectors.  I have to think it more. For the moment, suppose we only need 1 observable.</li></ul></p>
<p><ul style="margin-left:0px;"><li>Probability is inside the model from the beginning .... it can be added the other sense of probability......... I think</li></ul></p>
<p><ul style="margin-left:0px;"><li>The observables can be embedded in a <a href="./../♾️ CONCEPTS/c-star algebra.md.html">c-star algebra</a> $\mathcal A$ which in general is not commutative. I guess that the <a href="./../♾️ CONCEPTS/Gelfand spectrum.md.html">Gelfand spectrum</a> in this case is the original Hilbert space (pure states). The set of observables corresponds to the subset of $*$-invariant elements of $\mathcal{A}$.</li></ul></p>
<p><ul style="margin-left:0px;"><li>Dynamical law: since states have length 1, the dynamical</li></ul></p>
<p></p>
<h3 style="margin-left:0px;" id="Summary">Summary </h3>
<p>So to summarize, we can say that:</p>
<p>1. A system (classical system or quantum system) is given by a <a href="./../♾️ CONCEPTS/c-star algebra.md.html">c-star algebra</a> $\mathcal{A}$. A subset of $\mathcal{A}$ (the $*$-invariants elements) are the observables.  </p>
<p>2. Systems can be set on pure states or mixed states. The latter ones are interpreted as a kind of "combination" of the former ones, or better said, probability distributions of them. They are all <a href="./../♾️ CONCEPTS/positive functional.md.html">positive</a> normalized linear functionals on $\mathcal{A}$. The pure states are required to be also multiplicative (also called <a href="./../♾️ CONCEPTS/Gelfand spectrum.md.html">characters</a>).</p>
<p>3. In the case of a classical system the algebra is commutative. The multiplicative functionals constitute the <a href="./../♾️ CONCEPTS/Gelfand spectrum.md.html">Gelfand spectrum</a> of $\mathcal{A}$, which is a compact topological space representing the pure states. The rest of the normalized functionals correspond to probability distributions defined on the Gelfand spectrum of $\mathcal{A}$. For pure states, the probability distribution is typically described by a delta function concentrated at a single point in the phase space. This corresponds to the fact that the system is in a definite state, with the position and momentum of each particle in the system being well-defined.</p>
<p>4. In the case of quantum systems, the algebra is not commutative. The multiplicative functionals (pure states) constitute again the Gelfand spectrum of $\mathcal{A}$, which in many important cases, is a complex projective space with an underlying Hilbert space. They can be also interpreted as one-dimensional projections in the algebra, while the general normalized functionals (mixed states) are represented by density matrices, which are positive semi-definite operators with trace equal to 1.  I have to think this yet.</p>
<p></p>
<p></p>
<h3 style="margin-left:0px;" id="Quantum_physics_as_a_generalization_of_classical_physics">Quantum physics as a generalization of classical physics</h3>
<p>We can embed MM1 into MM2 in the following way: </p>
<p><ul style="margin-left:0px;"><li>$\Omega$ goes to $\mathbb P \mathbb C^n$, si cardinal de $\Omega$ es $n$</li></ul></p>
<p><ul style="margin-left:0px;"><li>$f:\Omega \to \mathbb C$ goes to the linear map</li></ul></p>
$$
M_f:\mathbb C^n \longmapsto \mathbb C^n
$$
<p>defined like the diagonal matrix whose entries are the values of $f$.</p>
<p><ul style="margin-left:0px;"><li>and so on... (I have to write this better)</li></ul></p>
<p><ul style="margin-left:0px;"><li>...</li></ul></p>
<p></p>
<p>But, why do we care about this embedding of MM1 into MM2? Why don't we settle for MM1? See this note: <a href="./Why did physics go quantum.md.html">Why did physics go quantum</a> </p>
<p></p>
<p><b>To review and maybe incorporate</b>: as it is said in <a href="https://mathoverflow.net/questions/6200/what-is-quantization/6216#6216" target="_blank">this MO answer</a> the point of QM is to see the algebra of functions as "immersed" in a bigger not necessarily commutative algebra. </p>
<p></p>
<p></p>
<hr>
<p></p>
<p></p>
<h1 style="margin-left:0px;" id="Old_latex_notes,_to_incorporate_above_one_day...">Old latex notes, to incorporate above one day...</h1>
<p></p>
<h2 style="margin-left:0px;" id="With_classical_probability">With classical probability</h2>
<p>We are going to analyse, from the beginning, the <a href="./Stern-Gerlach experiment.md.html">Stern-Gerlach experiment</a> from a mathematical viewpoint, and try to see why is natural the <a href="./formulation of QM.md.html">formulation of QM</a>. Imagine that electrons have an <b>internal configuration</b> that can be observed with a Stern-Gerlach device ($SG$) when they are shot with an electron gun. We align the machine with the $z$ axis (we call this configuration $SG_z$) and it gives us two outputs when electrons arrive: for example, <b>red</b> and <b>green</b>. Our first idea would be to think that there are two kinds of electrons or <b>two states of the electron</b>. </p>
<p></p>
<p>From the point of view of set theory, improved with basic probability theory, our first thought is: "ok, I have a set of electrons $\tilde{\Omega}$ and a map that sends their elements to the set $\{r,g\}$ with different frequencies. So, since there are (approximately) an infinite number of electrons, I can take a partition of $\tilde{\Omega}$ and shrink all data to a new set $\Omega=\{r,g\}$ with a probability measure $P$, and we would have no loss of information.</p>
<p></p>
<p>Then, we observe that if we have a copy of this machine and rotate it (or keep it fixed and rotate the gun that shoot the electrons in the opposite direction) to the $x$ axis (let's call $SG_x$ to this second machine) then we obtain two other outputs (<b>big</b> and <b>small</b>, for example) with a new probability distribution $P'$. If we assume a classical behavior of the states of the electron, i.e., we can use machine $SG_z$ on an electron and then machine $SG_x$ on the same electron and that does not change the <b>state</b> itself, we can obtain a joint probability distribution $\tilde{P}$, and conclude that there are four different states: </p>
$$
\Omega=\{rb, rs, gb, gs\}
$$
<p>with a new probability function. Our new set appears like a cartesian product of the previous "sets of possibilities".</p>
<p>Observe that the joint distribution is not necessarily</p>
$$
\tilde{P}(zx)=P(z)P'(x)
$$
<p>being this the case only when the variables are independent. For example, maybe there is a correlation between being red and being big.</p>
<p></p>
<h2 style="margin-left:0px;" id="A_different_approach">A different approach</h2>
<p>All of this could have been <b>translated to maths</b> in a very different way, far more complicated, but that it will pay off later.</p>
<p>A finite set $B$ with $N$ elements can be viewed as a <a href="./../♾️ CONCEPTS/FUNCTIONAL ANALYSIS/Hilbert space.md.html">Hilbert space</a></p>
$$
\ell^2(B) =\left\{ x:B \rightarrow \mathbb{C} \right\}=\mathbb{C}^N
$$
<p>with inner product</p>
$$
\langle x | y \rangle=\sum_{b \in B} x(b)y(b)
$$
<p>This way we have "enriched" the set: </p>
<p>1. we conserve the original elements of the set, codified in the rays through the canonical basis; but we get new objects, the <b>superposition</b> of the elements. This new objects may not have an interpretation for us, at a first glance. </p>
<p>2. And we also have a measure of "how <b>independent</b>" this objects are: the inner product. For example, the original elements are totally independent, for their inner product is 0.</p>
<p></p>
<p>Let's come back to Stern-Gerlach. Instead of thinking as before in the set $\Omega=\{r,g\}$, we take the Hilbert space</p>
$$
\mathcal{H}_1=\ell^2(\Omega)=\mathbb{C}^2
$$
<p>with the usual inner product. </p>
<p></p>
<p>The canonical basis elements of $\mathcal{H}_1$ (or better said, the rays through them) will represent the states $r$ and $g$, and the probability function $P$ will be encoded in a unitary vector $s_1 \in \mathcal{H}_1$ (or better said, the ray through it) in such a way that </p>
$$
P(r)=\|proj_r (s_1)\|_2^2=|\langle s_1 |r \rangle|^2=\langle s_1| proj_r(s_1) \rangle
$$
<p>represents the probability of obtaining the output $r$ when using the first machine. And the same for $g$. Observe that we are treating on an equal footing the states ($r$ or $g$) and the probability measure.</p>
<p></p>
<p>So far, two questions can arise:</p>
<p></p>
<p><ul style="margin-left:0px;"><li>We have chosen in $\mathcal{H}_1$ the <b>usual inner product</b> (equivalent to $\|\cdot \|_2$). Why not other inner product or even why not a more simple set up like an absolute value norm? That is, why don't we take, for example, $\|v\|_1=|v_1|+|v_2|$ and encode probabilities in $\|proj_r(s_1)\|_1$ without the square? Well, the only $p$-norm satisfying the <b>parallelogram rule</b> is $\|\cdot\|_2$, and this rule is needed to form an inner product from the norm. The finer approach of inner product will be needed later because it let us use further mathematics concepts (orthogonality, unitary Lie groups,...). Moreover, even intuitively the inner product approach is desirable because it gives us a measurement of the independence of the elements represented by the rays in the Hilbert space.</li></ul></p>
<p></p>
<p><ul style="margin-left:0px;"><li>Why don't we use real numbers and take as probabilities the absolute values of the component instead of the square? Once we fix the use of the 2-norm, we need to deal with <b>amplitudes</b> (i.e., numbers whose square give probabilities) because we want to keep with us the <b>addition of probabilities for incompatible events</b>, from the classical setup.<img src="./../imagenes/Pasted image 20220619085248.png" style="width:80vw; border-radius: 3px;" ></li></ul></p>
<p><ul style="margin-left:0px;"><li>And also, <a href="./why complex numbers in QM.md.html">why complex numbers in QM</a>?</li></ul></p>
<p></p>
<p>Within this approach to sets as Hilbert spaces, <b>subsets are encoded as subspaces</b>, the <b>union of sets is translated as the direct sum of subspaces</b>, <b>intersection of sets as intersections</b> of subspaces and the <b>complement of a set as the orthogonal complement</b> of the subspace.</p>
<p></p>
<h2 style="margin-left:0px;" id="Random_variables_vs_operators">Random variables vs operators</h2>
<p>Let's continue with $(\mathcal{H}_1, \langle | \rangle{}{})$. If we had numerical data instead of qualitative one (i.e., suppose that instead of "red" and "green", our machine give us two fixed values 0'7 and 1'8, or in other words, a random variable) we would codify this, within this new approach, in the idea of an operator. That is, a linear map</p>
$$
F:\mathcal{H}_1 \longmapsto\mathcal{H}_1
$$
<p>such that</p>
$$
F(r)=0'7 r; F(g)=1'8 g
$$
<p>i.e.,</p>
$$
F=\begin{pmatrix}
0'7 & 0\\ 
0 & 1'8
\end{pmatrix}
$$
<p>The random variable registers the idea of a <b>measurement</b>. This new approach to them may look very artificial, but it retains the same information that the classical probability approach:</p>
<p><ul style="margin-left:0px;"><li>We recuperate the values, for example for $r$, with</li></ul></p>
$$
\langle r | F(r)\rangle
$$
<p><ul style="margin-left:0px;"><li>The expected value of $F$, provided that probabilities are given by the vector $s_1$, would be</li></ul></p>
$$
\langle s_1| F(s_1)\rangle
$$
<p>When we take our second machine $SG_x$ we have other Hilbert space, say $\mathcal{H}_2$, and other state $s_2 \in \mathcal{H}_2$ encoding probabilities of $b$ and $s$. Suppose that this machine also gives numerical values, so that we have another operator $G:\mathcal{H}_2\mapsto \mathcal{H}_2$, also diagonal in the canonical basis of $\mathcal{H}_2$.</p>
<p>If we assume, as before, a classical behavior of the states, we can model this with a new Hilbert space</p>
$$
\mathcal{H}=\mathcal{H}_1 \otimes \mathcal{H}_2
$$
<p>whose basis will be denoted by $\{rb, rs, gb, gs\}$. This <a href="./../♾️ CONCEPTS/tensor product.md.html">tensor product</a>  plays the role of cartesian product in the previous set up.</p>
<p></p>
<p>We can think that the state describing the system would be</p>
$$
s_1 \otimes s_2
$$
<p>but in fact this is only an special case when the two machines are yielding the equivalent to "independent variables" (the joint probability is the product of the probabilities). In general, it is valid any $\Psi \in \mathcal{H}_1 \otimes \mathcal{H}_2$ provided that the coefficients in the linear combination</p>
$$
\Psi=a_1 rb+a_2 rs+a_3 gb+a_4 gs
$$
<p>are such that</p>
$$
|a_1|^2+|a_2|^2=P(r)
$$
$$
|a_3|^2+|a_4|^2=P(g)
$$
$$
|a_1|^2+|a_3|^2=P(b)
$$
$$
|a_2|^2+|a_4|^2=P(s)
$$
$$
|a_1|^2+|a_2|^2+|a_3|^2+|a_4|^2=1
$$
<p>where the second and the fourth equations could be deduced, so we can remove it.</p>
<p><img src="./../imagenes/Pasted image 20220619093717.png" style="width:80vw; border-radius: 3px;" ></p>
<p>The random variable represented by the operator $F$ corresponds here to $F\otimes Id$ (<a href="./../♾️ CONCEPTS/tensor product.md.html#Kronecker_product">Kronecker product</a>), and $G$ to $Id \otimes G$.</p>
<p></p>
<h2 style="margin-left:0px;" id="Quantum_behavior">Quantum behavior</h2>
<p>We are yet in a classical set up, but now we are going to <b>jump to the quantum behavior</b>. Nevertheless, what have been said so far would be valid, even in QM, for observables that are "totally independent" (own terminology), for example, $x$ position and $y$ position. I think the technical name is commuting observables.</p>
<p></p>
<p>Suppose that after measuring an electron with the first device we obtain $r$. Then we use the second one and obtain $b$. In a classical setup we would expect that if we use device 1 again, we obtain $r$ again, but this is not what happens with Stern-Gerlach devices. We obtain $r$ and $g$ with certain frequencies (although fixed).</p>
<p></p>
<p>The logical explanation (at least from the point of view of QM) is to accept that electron <b>is</b> in a certain state $\Psi \in \mathcal{H}_1$ before the use of any machine. Until now, we have assumed that the vector in the Hilbert space encodes probabilities. But now we are saying that <b>the electron is the vector</b> (or, at least, a part of the electron). Every time we use a machine, the vector $\Psi$ <b>moves to a new location</b>. For example: we use machine 1 and get $r$ or $0'7$ (with certain probability), so the state vector has travelled to $r$. If we use machine 1 again we obtain the same result: probability of obtain $r$ again is the length of the projection of $r$ on $r$, that is, 1!! If we use machine 2, depending on the value obtained, the state vector travels to $b$ or $s$ but they are still inside $\mathcal{H}_1$. </p>
<p></p>
<p>That is, we have machines (or one machine with different positions) that extract information of the system. The system is codified in a Hilbert space and the machines in operators. Every operator has <b>privileged states</b> with good behavior respect to it (a "classic behavior" respect to it, we can say). That is the reason why we cannot consider any operator, but the corresponding to <a href="./../♾️ CONCEPTS/Hermitian matrix.md.html">Hermitian matrices</a>. </p>
<p>If the system is in a "classical state" for the operator, the operator will only change the scale of the state vector, and the measurement arises when we check the length of the transformed vector</p>
$$
\langle r|F(r) \rangle.
$$
<p>If the system is in a "non-classical" state for this machine, it goes to the "most similar" classical state for the machine (not for sure, but with a probability that depends on the similitude), and then the above is applied.</p>
<p></p>
<p>Can we find the expression of the privileged states of a machine with respect of the ones of the other? That is, who are $b$ and $s$ (canonical base for machine 2) in the canonical base of $\mathcal{H}_1$? </p>
<p></p>
<p>Suppose the machines are $SG_z$ and $SG_x$ in the Stern-Gerlach experiments. According to the <b>measured probabilities</b> in <a href="./Stern-Gerlach experiment.md.html">Stern-Gerlach experiment</a> we could assign the coefficients:</p>
$$
b=\frac{1}{\sqrt{2}} r+\frac{1}{\sqrt{2}}g
$$
$$
s=\frac{1}{\sqrt{2}} r-\frac{1}{\sqrt{2}}g
$$
<p>The choice of the coefficients is arbitrary but subject to the measured probabilities. </p>
<p>Observe that, so far, we have no need of complex numbers. </p>
<p>Of course, the operator $SG_z$ has the matrix expression in "its associated basis" is (we are assuming now that the outputs are 1 and -1 instead of 0'7 and 1'8):</p>
$$
SG_z \equiv \begin{pmatrix}
1&0 \\ 
0& -1
\end{pmatrix}
$$
<p>What is the matrix expression for the $SG_x$ machine in this basis? Since $SG_x b=b$ and $SG_x s=-s$, solving a very easy linear system we find that</p>
$$
SG_x \equiv \begin{pmatrix}
0&1 \\ 
1& 0
\end{pmatrix}
$$
<p>But we can think like if we have an infinite number of machines $SG_{\theta}$. They are all the same that our original $SG_z$ but rotated an angle $\theta$ from the $z$ axis towards the $x$ axis. For the moment, we will be pretending that the universe is of dimension 2. With each of these machines we get two results, say $M$ and $B$, and <b>empirically</b> obtain that, once our system is in state $M$, $SG_z$ yields an expected value of $cos(\theta)$, what is reasonable even from the classical point of view. If we write $M=\alpha r +\beta g$ and $B=\gamma r+ \delta g$, since</p>
$$
\langle M |SG_z(M) \rangle=cos(\theta)
$$
<p>(expected value) and $M$ is normalized, i.e., </p>
$$
\langle M|M \rangle=1
$$
<p>we obtain </p>
$$
M=cos(\frac{\theta}{2}) r+ sin(\frac{\theta}{2}) g
$$
<p>In a similar way, since the expected value for $B$ is $-cos(\theta)$ and $M$ and $B$ must be orthogonal we can conclude</p>
$$
B=-sin(\frac{\theta}{2}) r+ cos(\frac{\theta}{2}) g
$$
<p>Solving a linear system we find the matrix for $SG_{\theta}$:</p>
$$
SG_{\theta} \equiv \begin{pmatrix}
cos(\theta)&sin(\theta) \\ 
sin(\theta)& -cos(\theta)
\end{pmatrix}
$$
<p>So, in conclusion, we can assume that when we rotate the $SG_z$ machine an angle $\theta$ the well-behaved states are now</p>
<p></p>
$$
\begin{pmatrix}
cos(\frac{\theta}{2}) \\ 
sin(\frac{\theta}{2}) 
\end{pmatrix}, \begin{pmatrix}
-sin(\frac{\theta}{2}) \\ 
cos(\frac{\theta}{2}) 
\end{pmatrix}
$$
<p>that is, the privileged vectors are rotated an angle of $\theta/2$. Or we can interpret that if we rotate the system (our electron gun in state $r=\begin{pmatrix}1 \\0 \end{pmatrix}$) an angle of $-\theta$, we are putting the electron in a state </p>
$$
\begin{pmatrix}
cos(\frac{\theta}{2}) \\ 
-sin(\frac{\theta}{2}) 
\end{pmatrix} \in \mathcal{H}
$$
<p>And the operator goes from </p>
$$
\begin{pmatrix}
1&0\\ 
0&-1
\end{pmatrix}
$$
<p>to</p>
$$
\begin{pmatrix}
cos(\theta)&sin(\theta) \\ 
sin(\theta)& -cos(\theta)
\end{pmatrix}
$$
<p>This <b>let us predict probabilities</b> in the <a href="./Stern-Gerlach experiment.md.html">Stern-Gerlach experiment</a>: what would be the probability of obtain such result if we turn the machine such angle? It is a numerical model for this family of Stern-Gerlach experiments.</p>
<p></p>
<p>But we can think in it like a geometric model, too. The different directions of space (plane, in this case) are codified in the matrices $SG_{\theta}$: $SG_z$ would represent the unit vector along $z$ axis, and $SG_{\theta}$ is the result of a rotation of angle $\theta$.  And we are led to think that spin is an "internal object" inside the electron with a special kind of symmetry without counterpart in classical-macroscopic terms.  </p>
<p>(see section \textit{About spin})</p>
<p><img src="./../imagenes/Pasted image 20220619120550.png" style="width:80vw; border-radius: 3px;" ></p>
<p>So, what about our electron? After performing a rotation of angle $\theta$ the privileged states of the Hilbert space have rotated $\theta/2$ so we come back to the initial configuration after a $4\pi$ rotation. So we can say that electron has spin 1/2. It is a bit difficult to visualize but you can imagine an arrow with a flag attached in such a way that the flag turns half the angle of the arrow.</p>
<p></p>
<p>On the other hand, observe that the matrices </p>
$$ 
SG_z=\begin{pmatrix}
1&0 \\ 
0& -1
\end{pmatrix},\quad SG_x=\begin{pmatrix}
0&1 \\ 
1& 0
\end{pmatrix}
$$
<p>behaves like a orthogonal vector basis of $\mathbb{R}^2$. In fact</p>
$$
R^{\theta}(SG_z)=\begin{pmatrix}
\cos(\theta)&-\sin(\theta) \\ 
sin(\theta)& cos(\theta)
\end{pmatrix} \cdot\begin{pmatrix}
1&0 \\ 
0& -1
\end{pmatrix}=
$$
$$
=\begin{pmatrix}
\cos(\theta)&\sin(\theta) \\ 
\sin(\theta)& -\cos(\theta)
\end{pmatrix}=\cos(\theta) SG_z + \sin(\theta) SG_x
$$
<p>among other similarities. But the matrices product gives them an additional intrinsic algebra structure which the vector space $\mathbb{R}^2$ lacks. What does it mean, geometrically? </p>
<p></p>
<p>There is a correspondence between the subalgebra generated by the matrices $\{SG_z, SG_x\}$ and the abstract Clifford algebra of dimension 2 and positive signature with orthonormal basis $\{e_1, e_2\}$. Since we know that in the Clifford algebra the even subalgebra acts over $\mathbb{R}^2$ like rotations (on the "sandwich way") we are led to think that internal states of the electron are elements of $\mathcal{G}_2^+$, that is, spinors. That is, the element </p>
$$
cos(\frac{\theta}{2}) 1 + sin(\frac{\theta}{2}) e_1 e_2 \in \textrm{Cl}_2(\mathbb{R})
$$
<p>is identified with the pair of elements of the Hilbert space</p>
$$
\begin{pmatrix}
cos(\frac{\theta}{2}) \\ 
sin(\frac{\theta}{2}) 
\end{pmatrix}, \begin{pmatrix}
-sin(\frac{\theta}{2}) \\ 
cos(\frac{\theta}{2}) 
\end{pmatrix}
$$
<p>One observation: the even subalgebra behaves like complex numbers. So the complex numbers have already entered the scene.</p>
<p></p>
<p></p>
<h2 style="margin-left:0px;" id="The_3-dimensional_space">The 3-dimensional space</h2>
<p>But the Universe is not planar, is 3D. What happens when we rotate the machine out of the $xz$-plane? Experiments show that the pure $y$ orientation of the machine ($SG_y$) yields a pair of states, call it <b>head</b> and <b>tail</b>, $h$ and $t$, with probabilities <b>similar to</b> those of the $SG_x$ ($b$ and $s$) when throwed through $SG_z$. But keep an eye: further experiments show that those <b>are not</b> the privileged states of $SG_x$. This cannot be, definitively, modelled if we stay with real numbers (see page <a href="./Why complex numbers in QM.md.html">Why complex numbers in QM</a>).</p>
<p>We can solve this problem by using complex coefficients, and in this way we arrive to the picture of the internal states as elements of $SU(2)$. Indeed, the measured probabilities together with the restrictions of orthonormality of $h$ and $t$ lead us to</p>
$$
h=\frac{1}{\sqrt{2}} r+\frac{e^{i\alpha}}{\sqrt{2}}g
$$
$$
t=\frac{1}{\sqrt{2}} r-\frac{e^{i\alpha}}{\sqrt{2}}g
$$
<p>If we now measure probabilities respect to $SG_x$ (i.e., probabilities of $b$ and $s$ output when we feed the machine with $h$ or $t$ states) we can find that $\alpha=\pi/2$. That is,</p>
$$
h=\frac{1}{\sqrt{2}} r+\frac{i}{\sqrt{2}}g
$$
$$
t=\frac{1}{\sqrt{2}} r-\frac{i}{\sqrt{2}}g
$$
<p>And with some computations we get</p>
$$
SG_y \equiv \begin{pmatrix}
0&-i \\ 
i& 0
\end{pmatrix}
$$
<p>The matrices $SG_x, SG_y, SG_z$ are called Pauli matrices.</p>
<p></p>
<p>In conclusion, we have a machine, $SG$, that can be oriented in any spatial direction, $\hat{n}$ (unitary vector). When we fix this direction we get a matrix, $SG_{\hat{n}}$, that encodes all the data of the machine (final states, obtained values and probabilities) with this direction. This matrix has two eigenvectors of $\mathbb{C}^2$, $\ket{n+}$ and $\ket{n-}$, that represent the state of the electron after passing through the machine. Or we can think that the device $SG$ is fixed, and we turn the electron gun to a new spatial orientation $\hat{n}$. Internally for the electron this has an effect: if it was at state </p>
$$
\begin{pmatrix}
1\\
0
\end{pmatrix}
$$
<p>it is arriving to a new state </p>
$$
\begin{pmatrix}
\alpha\\
\beta
\end{pmatrix} \in \mathcal{H}
$$
<p>that can be computed like this:</p>
<p><ul style="margin-left:0px;"><li>The rotation of the gun is performed with a $3\times 3$ orthogonal matrix $R\in SO(3)$, that can be viewed as an element of $SU(2)$ (in fact, there are two of them, since it is a double covering).</li></ul></p>
<p><ul style="margin-left:0px;"><li>In this assignation we can observe a kind of "miracle". The matrix $R$ can be obtained like the product of other three</li></ul></p>
$$
R=e^{\alpha G_x}\cdot e^{\theta G_y}\cdot e^{\phi G_z}
$$
<p>where $\{G_x, G_y, G_z\}$ are $3\times 3$ matrices forming a basis of $so(3)$. To find the corresponding element of $SU(2)$ we use the isomorphism (as Lie algebras) of $so(3)$ with $su(2)$, and then the exponential map over $SU(2)$. And the miracle is that the images of $G_x,G_y,G_z$ are</p>
$$
\frac{i}{2} SG_x, \frac{i}{2} SG_y,\frac{i}{2} SG_z
$$
<p>although this matrices (without the $i$) appeared like operators to encode data of an observable, not like transformations!!!</p>
<p></p>
<p><ul style="margin-left:0px;"><li>The obtained element of $SU(2)$ rotates the initial "internal vector" $\begin{pmatrix}1\\0\end{pmatrix}$ in the usual way: complex matrix product.</li></ul></p>
<p><ul style="margin-left:0px;"><li>If we had chosen the other element of $SU(2)$ we would have arrived to other vector in $\mathcal{H}$. But the states are not elements of $\mathcal{H}$, but of $\mathbb{P}(\mathcal{H})$.</li></ul></p>
<p></p>
<p>Some considerations to further thoughts:</p>
<p><ul style="margin-left:0px;"><li>The element of $SU(2)$ applied in the sandwhich way to the matrices $SG_n$ rotates them, i.e., gives the same result that applying an usual 2x2 rotation matrix on the left. This aims to think the matrices $SG_n$ like vectors...</li></ul></p>
<p><ul style="margin-left:0px;"><li>In the point 2 above we watch that $i SG_n$ behaves like bivectors in a Clifford algebra, so here is other reason to think that $SG_n$ are vectors.</li></ul></p>
<p><ul style="margin-left:0px;"><li>All would be, therefore, simpler if we forget the Pauli matrices and go to Clifford algebras¿?</li></ul></p>
<p><ul style="margin-left:0px;"><li>Explicit computations can be found at mathematica file \textbf{quantum computations SPIN12}</li></ul></p>
<p>________________________________________</p>
<p>________________________________________</p>
<p>________________________________________</p>
<p>Author of the notes: Antonio J. Pan-Collantes<br>
<p><a href="mailto:antonio.pan@uca.es">antonio.pan@uca.es</a></p><br>
<p>INDEX:<br>
	<iframe src="../treeview.html" width="90%" frameBorder="0" height="900px"></iframe>
</font></div>
</body>
</html>
